{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Validation of gens_eia860\n",
    "This notebook runs sanity checks on the Generators data that are reported in EIA Form 860. These are the same tests which are run by the gens_eia860 validation tests by PyTest.  The notebook and visualizations are meant to be used as a diagnostic tool, to help understand what's wrong when the PyTest based data validations fail for some reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pudl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "pd.options.display.max_columns = 56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_settings = pudl.workspace.setup.get_defaults()\n",
    "ferc1_engine = sa.create_engine(pudl_settings['ferc1_db'])\n",
    "pudl_engine = sa.create_engine(pudl_settings['pudl_db'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the original EIA 860 data\n",
    "First we pull the original (post-ETL) EIA 860 data out of the database. We will use the values in this dataset as a baseline for checking that latter aggregated data and derived values remain valid.  We will also eyeball these values here to make sure they are within the expected range. This may take a minute or two depending on the speed of your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl_out_orig = pudl.output.pudltabl.PudlTabl(pudl_engine, freq=None)\n",
    "gens_eia860_orig = pudl_out_orig.gens_eia860()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Validation Against Fixed Bounds \n",
    "Some of the variables reported in this table have a fixed range of reasonable values, like the capacity.  These varaibles can be tested for validity against external standards directly.  In general we have two kinds of tests in this section:\n",
    "* **Tails:** are the exteme values too extreme? Typically, this is at the 5% and 95% level, but depending on the distribution, sometimes other thresholds are used.\n",
    "* **Middle:** Is the central value of the distribution where it should be?\n",
    "\n",
    "### Fields that need checking:\n",
    "The main column we are checking right now is the capacity.\n",
    "\n",
    "Future data-like columns to potentially check:\n",
    "  - 'minimum_load_mw'\n",
    "  - 'nameplate_power_factor'\n",
    "  - 'planned_net_summer_capacity_derate_mw'\n",
    "  - 'planned_net_summer_capacity_uprate_mw'\n",
    "  - 'planned_net_winter_capacity_derate_mw'\n",
    "  - 'planned_net_winter_capacity_uprate_mw'\n",
    "  - 'planned_new_capacity_mw'\n",
    "  - 'summer_capacity_mw'\n",
    "  - 'winter_capacity_mw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gens_eia860_orig.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl.validate.plot_vs_bounds(gens_eia860_orig, pudl.validate.gens_eia860_vs_bound)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Historical Distributions\n",
    "As a sanity check of the testing process itself, we can check to see whether the entire historical distribution has attributes that place it within the extremes of a historical subsampling of the distribution. In this case, we sample each historical year, and look at the range of values taken on by some quantile, and see whether the same quantile for the whole of the dataset fits within that range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pudl.validate.plot_vs_self(gens_eia860_orig, pudl.validate.gens_eia860_self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
