{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "import pudl\n",
    "import pudl.constants as pc\n",
    "from pudl.analysis.state_demand import (\n",
    "    load_ferc714_hourly_demand_matrix,\n",
    "    clean_ferc714_hourly_demand_matrix,\n",
    "    filter_ferc714_hourly_demand_matrix,\n",
    "    impute_ferc714_hourly_demand_matrix,\n",
    "    melt_ferc714_hourly_demand_matrix,\n",
    "    load_counties,\n",
    "    load_ferc714_county_assignments,\n",
    "    load_eia861_state_total_sales,\n",
    "    predict_state_hourly_demand,\n",
    "    plot_demand_timeseries,\n",
    "    plot_demand_scatter,\n",
    "    load_ventyx_hourly_state_demand,\n",
    "    lookup_state,\n",
    "    compare_state_demand,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY_EIA = os.environ[\"API_KEY_EIA\"]\n",
    "API_KEY_BLS = os.environ[\"API_KEY_BLS\"]\n",
    "API_KEY_FRED = os.environ[\"API_KEY_FRED\"]\n",
    "#HARVEST_TOKEN = os.environ[\"HARVEST_TOKEN\"]\n",
    "#HARVEST_ACCOUNT_ID = os.environ[\"HARVEST_ACCOUNT_ID\"]\n",
    "\n",
    "from pudl.workspace.setup import PudlPaths\n",
    "ferc1_engine = sa.create_engine(PudlPaths().sqlite_db_uri(\"ferc1\"))\n",
    "pudl_engine = sa.create_engine(PudlPaths().pudl_db)\n",
    "pudl_out = pudl.output.pudltabl.PudlTabl(pudl_engine=pudl_engine)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the FERC 714 data\n",
    "* Should take ~1 minute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df1, tz = load_ferc714_hourly_demand_matrix(pudl_out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean the FERC 714 hourly demand matrix\n",
    "* This uses ~32GB of memory.\n",
    "* Takes ~10 minutes.\n",
    "* Why the `RuntimeWarning` about an All-NaN slice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df2 = clean_ferc714_hourly_demand_matrix(df1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove respondents lacking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df3 = filter_ferc714_hourly_demand_matrix(df2, min_data=100, min_data_fraction=0.9)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing demand values.\n",
    "* Very CPU intensive, takes ~1 hour and maxes out all 4 of my cores.\n",
    "* Not very memory intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df4 = impute_ferc714_hourly_demand_matrix(df3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Melt FERC 714 hourly demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "demand = melt_ferc714_hourly_demand_matrix(df4, tz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "counties = load_counties(pudl_out, pudl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "assignments = load_ferc714_county_assignments(pudl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "state_totals = load_eia861_state_total_sales(pudl_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "prediction = predict_state_hourly_demand(\n",
    "    demand,\n",
    "    counties=counties,\n",
    "    assignments=assignments,\n",
    "    state_totals=state_totals,\n",
    "    mean_overlaps=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import pathlib\n",
    "local_dir = PudlPaths().data_dir / 'local'\n",
    "ventyx_path = local_dir / 'ventyx/state_level_load_2007_2018.csv'\n",
    "base_dir = local_dir / 'state-demand'\n",
    "base_dir.mkdir(parents=True, exist_ok=True)\n",
    "demand_path = base_dir / 'demand.csv'\n",
    "stats_path = base_dir / 'demand-stats.csv'\n",
    "timeseries_dir = base_dir / 'timeseries'\n",
    "timeseries_dir.mkdir(parents=True, exist_ok=True)\n",
    "scatter_dir = base_dir / 'scatter'\n",
    "scatter_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Write predicted hourly state demand\n",
    "prediction.to_csv(\n",
    "    demand_path, index=False, date_format='%Y%m%dT%H', float_format='%.1f'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load Ventyx as reference if available\n",
    "reference = None\n",
    "if ventyx_path.exists():\n",
    "    reference = load_ventyx_hourly_state_demand(ventyx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Plots and statistics\n",
    "stats = []\n",
    "for fips in prediction['state_id_fips'].unique():\n",
    "    state = lookup_state(fips)\n",
    "    # Filter demand by state\n",
    "    a = prediction.query(f'state_id_fips == {fips}')\n",
    "    b = None\n",
    "    title = f'{state[\"fips\"]}: {state[\"name\"]} ({state[\"code\"]})'\n",
    "    plot_name = f'{state[\"fips\"]}-{state[\"name\"]}.png'\n",
    "    if reference is not None:\n",
    "        b = reference.query(f'state_id_fips == {fips}')\n",
    "    # Save timeseries plot\n",
    "    plot_demand_timeseries(\n",
    "        a, b=b, window=168, title=title, path=timeseries_dir / plot_name\n",
    "    )\n",
    "    if b is None or b.empty:\n",
    "        continue\n",
    "    # Align predicted and reference demand\n",
    "    a = a.set_index('utc_datetime')\n",
    "    b = b.set_index('utc_datetime')\n",
    "    index = a.index.intersection(b.index)\n",
    "    a = a.loc[index].reset_index()\n",
    "    b = b.loc[index].reset_index()\n",
    "    # Compute statistics\n",
    "    stat = compare_state_demand(a, b, scaled=True)\n",
    "    stat['state_id_fips'] = fips\n",
    "    stats.append(stat)\n",
    "    # Save scatter plot\n",
    "    plot_demand_scatter(a, b=b, title=title, path=scatter_dir / plot_name)\n",
    "\n",
    "# Write statistics\n",
    "if reference is not None:\n",
    "    pd.concat(stats, ignore_index=True).to_csv(\n",
    "        stats_path, index=False, float_format='%.1f'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
