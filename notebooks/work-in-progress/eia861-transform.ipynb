{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Create a Mega EIA861 Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, the EIA861 data is only partially integrated into the ETL pipeline. We have created temporary output tables to access the transformed data more easily. This notebook combines the information from these tables into one mega spreadsheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "# 3rd party libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sqlalchemy as sa\n",
    "from functools import reduce\n",
    "\n",
    "# Local libraries\n",
    "import pudl\n",
    "import pudl.constants as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.figsize'] = (10,4)\n",
    "mpl.rcParams['figure.dpi'] = 150\n",
    "pd.options.display.max_columns = 100\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "handler = logging.StreamHandler(stream=sys.stdout)\n",
    "formatter = logging.Formatter('%(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.handlers = [handler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load Output Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eia861_dfs = {\n",
    "    \"service_territory_eia861\": pudl_out.service_territory_eia861(),\n",
    "    \"balancing_authority_eia861\": pudl_out.balancing_authority_eia861(),\n",
    "    \"sales_eia861\": pudl_out.sales_eia861(),\n",
    "    \"advanced_metering_infrastructure_eia861\": pudl_out.advanced_metering_infrastructure_eia861(),\n",
    "    \"demand_response_eia861\": pudl_out.demand_response_eia861(),\n",
    "    \"demand_response_water_heater_eia861\": pudl_out.demand_response_water_heater_eia861(),\n",
    "    \"demand_side_management_sales_eia861\": pudl_out.demand_side_management_sales_eia861(),\n",
    "    \"demand_side_management_ee_dr_eia861\": pudl_out.demand_side_management_ee_dr_eia861(),\n",
    "    \"demand_side_management_misc_eia861\": pudl_out.demand_side_management_misc_eia861(),\n",
    "    \"distributed_generation_tech_eia861\": pudl_out.distributed_generation_tech_eia861(),\n",
    "    \"distributed_generation_fuel_eia861\": pudl_out.distributed_generation_fuel_eia861(),\n",
    "    \"distributed_generation_misc_eia861\": pudl_out.distributed_generation_misc_eia861(),\n",
    "    \"distribution_systems_eia861\": pudl_out.distribution_systems_eia861(),\n",
    "    \"dynamic_pricing_eia861\": pudl_out.dynamic_pricing_eia861(),\n",
    "    \"energy_efficiency_eia861\": pudl_out.energy_efficiency_eia861(),\n",
    "    \"green_pricing_eia861\": pudl_out.green_pricing_eia861(),\n",
    "    \"mergers_eia861\": pudl_out.mergers_eia861(),\n",
    "    \"net_metering_customer_fuel_class_eia861\": pudl_out.net_metering_customer_fuel_class_eia861(),\n",
    "    \"net_metering_misc_eia861\": pudl_out.net_metering_misc_eia861(),\n",
    "    \"non_net_metering_customer_fuel_class_eia861\": pudl_out.non_net_metering_customer_fuel_class_eia861(),\n",
    "    \"non_net_metering_misc_eia861\": pudl_out.non_net_metering_misc_eia861(),\n",
    "    \"operational_data_revenue_eia861\": pudl_out.operational_data_revenue_eia861(),\n",
    "    \"operational_data_misc_eia861\": pudl_out.operational_data_misc_eia861(),\n",
    "    \"reliability_eia861\": pudl_out.reliability_eia861(),\n",
    "    \"utility_data_nerc_eia861\": pudl_out.utility_data_nerc_eia861(),\n",
    "    \"utility_data_rto_eia861\": pudl_out.utility_data_rto_eia861(),\n",
    "    \"utility_data_misc_eia861\": pudl_out.utility_data_misc_eia861(),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Combine Output Tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_cols = [\n",
    "    'utility_id_eia',\n",
    "    'state',\n",
    "    'report_date',\n",
    "]\n",
    "idx_ba = util_cols + ['balancing_authority_code_eia']\n",
    "idx_nr = util_cols + ['nerc_region']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get rid of 2019 unnamed col for new data\n",
    "for df_name, df in eia861_dfs.items():\n",
    "    if 'unnamed_0' in df.columns:\n",
    "        eia861_dfs[df_name] = df.drop('unnamed_0', axis=1)\n",
    "\n",
    "# Fix reliability col to say standard\n",
    "eia861_dfs['reliability_eia861'] = (\n",
    "    eia861_dfs['reliability_eia861'].rename(columns={'standard': 'standards_class'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run this kernel to reset the dict\n",
    "table_dict = {\n",
    "    'advanced_metering_infrastructure_eia861': eia861_dfs['advanced_metering_infrastructure_eia861'].copy(),\n",
    "     #'balancing_authority_assn_eia861',\n",
    "     #'balancing_authority_eia861': eia_transformed_dfs['balancing_authority_eia861'].copy(),\n",
    "     'demand_response_eia861': eia861_dfs['demand_response_eia861'].copy(),\n",
    "     'demand_response_water_heater_eia861': eia861_dfs['demand_response_water_heater_eia861'].copy(),\n",
    "     'demand_side_management_ee_dr_eia861': eia861_dfs['demand_side_management_ee_dr_eia861'].copy(),\n",
    "     'demand_side_management_misc_eia861': eia861_dfs['demand_side_management_misc_eia861'].copy(),\n",
    "     'demand_side_management_sales_eia861': eia861_dfs['demand_side_management_sales_eia861'].copy(),\n",
    "     'distributed_generation_fuel_eia861': eia861_dfs['distributed_generation_fuel_eia861'].copy(),\n",
    "     'distributed_generation_misc_eia861': eia861_dfs['distributed_generation_misc_eia861'].copy(),\n",
    "     'distributed_generation_tech_eia861': eia861_dfs['distributed_generation_tech_eia861'].copy(),\n",
    "     'distribution_systems_eia861': eia861_dfs['distribution_systems_eia861'].copy(),\n",
    "     'dynamic_pricing_eia861': eia861_dfs['dynamic_pricing_eia861'].copy(),\n",
    "     'energy_efficiency_eia861': eia861_dfs['energy_efficiency_eia861'].copy(),\n",
    "     'green_pricing_eia861': eia861_dfs['green_pricing_eia861'].copy(),\n",
    "     'mergers_eia861': eia861_dfs['mergers_eia861'].copy(),\n",
    "     'net_metering_customer_fuel_class_eia861': eia861_dfs['net_metering_customer_fuel_class_eia861'].copy(),\n",
    "     'net_metering_misc_eia861': eia861_dfs['net_metering_misc_eia861'].copy(),\n",
    "     'non_net_metering_customer_fuel_class_eia861': eia861_dfs['non_net_metering_customer_fuel_class_eia861'].copy(),\n",
    "     'non_net_metering_misc_eia861': eia861_dfs['non_net_metering_misc_eia861'].copy(),\n",
    "     'operational_data_misc_eia861': eia861_dfs['operational_data_misc_eia861'].copy(),\n",
    "     'operational_data_revenue_eia861': eia861_dfs['operational_data_revenue_eia861'].copy(),\n",
    "     'reliability_eia861': eia861_dfs['reliability_eia861'].copy(),\n",
    "     'sales_eia861': eia861_dfs['sales_eia861'].copy(),\n",
    "     'service_territory_eia861': eia861_dfs['service_territory_eia861'].copy(),\n",
    "     #'utility_assn_eia861',\n",
    "     'utility_data_misc_eia861': eia861_dfs['utility_data_misc_eia861'].copy(),\n",
    "     'utility_data_nerc_eia861': eia861_dfs['utility_data_nerc_eia861'].copy(),\n",
    "     'utility_data_rto_eia861': eia861_dfs['utility_data_rto_eia861'].copy(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpeel_list = [\n",
    "    'advanced_metering_infrastructure_eia861',\n",
    "     #'balancing_authority_assn_eia861',\n",
    "     #'balancing_authority_eia861',\n",
    "     'demand_response_eia861',\n",
    "     'demand_response_water_heater_eia861',\n",
    "     'demand_side_management_ee_dr_eia861',\n",
    "     'demand_side_management_misc_eia861',\n",
    "     'demand_side_management_sales_eia861',\n",
    "     'distributed_generation_fuel_eia861',\n",
    "     'distributed_generation_misc_eia861',\n",
    "     'distributed_generation_tech_eia861',\n",
    "     'distribution_systems_eia861',\n",
    "     'dynamic_pricing_eia861',\n",
    "     'energy_efficiency_eia861',\n",
    "     'green_pricing_eia861',\n",
    "     'mergers_eia861',\n",
    "     'net_metering_customer_fuel_class_eia861',\n",
    "     'net_metering_customer_fuel_class_eia861', # because two classes\n",
    "     'net_metering_misc_eia861',\n",
    "     'non_net_metering_customer_fuel_class_eia861',\n",
    "     'non_net_metering_customer_fuel_class_eia861', # because two classes \n",
    "     'non_net_metering_misc_eia861',\n",
    "     'operational_data_misc_eia861',\n",
    "     'operational_data_revenue_eia861',\n",
    "     'reliability_eia861',\n",
    "     'sales_eia861',\n",
    "     'service_territory_eia861',\n",
    "     #'utility_assn_eia861',\n",
    "     'utility_data_misc_eia861',\n",
    "     'utility_data_nerc_eia861',\n",
    "     'utility_data_rto_eia861'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moniker_dict = {\n",
    "    'advanced_metering_infrastructure_eia861': 'AMI',\n",
    "     #'balancing_authority_assn_eia861',\n",
    "     #'balancing_authority_eia861',\n",
    "     'demand_response_eia861': 'DR',\n",
    "     'demand_response_water_heater_eia861': 'DR',\n",
    "     'demand_side_management_ee_dr_eia861': 'DSM',\n",
    "     'demand_side_management_misc_eia861': 'DSM',\n",
    "     'demand_side_management_sales_eia861': 'DSM',\n",
    "     'distributed_generation_fuel_eia861': 'DG',\n",
    "     'distributed_generation_misc_eia861': 'DG',\n",
    "     'distributed_generation_tech_eia861': 'DG',\n",
    "     'distribution_systems_eia861': 'DS',\n",
    "     'dynamic_pricing_eia861': 'DP',\n",
    "     'energy_efficiency_eia861': 'EE',\n",
    "     'green_pricing_eia861': 'GP',\n",
    "     'mergers_eia861': 'M',\n",
    "     'net_metering_customer_fuel_class_eia861': 'NM',\n",
    "     'net_metering_misc_eia861': 'NM',\n",
    "     'non_net_metering_customer_fuel_class_eia861': 'NNM',\n",
    "     'non_net_metering_misc_eia861': 'NNM',\n",
    "     'operational_data_misc_eia861': 'OD',\n",
    "     'operational_data_revenue_eia861': 'OD',\n",
    "     'reliability_eia861': 'R',\n",
    "     'sales_eia861': 'S',\n",
    "     'service_territory_eia861': 'ST',\n",
    "     #'utility_assn_eia861',\n",
    "     'utility_data_misc_eia861': 'UD',\n",
    "     'utility_data_nerc_eia861': 'UD',\n",
    "     'utility_data_rto_eia861': 'UD',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpeel(df, df_name, class_name):\n",
    "    \"\"\"Make single class name column into suffix for columns - tall-to-wide reformatting\"\"\"\n",
    "    logger.info(f'unpeeling {class_name} from {df_name} table')\n",
    "    # Include utility_id_eia in qualitative col grab (for index)\n",
    "    string_df = (\n",
    "        df[['utility_id_eia']]\n",
    "        .join(df.select_dtypes(exclude=['int64', 'float']))\n",
    "    )\n",
    "\n",
    "    class_name = class_name\n",
    "    qual_cols = list(string_df.columns)\n",
    "    qual_cols.remove(class_name)\n",
    "\n",
    "    wide_df = (\n",
    "        df.set_index(qual_cols)\n",
    "        .pivot(columns=class_name)\n",
    "    )\n",
    "    old_cols = list(wide_df.columns.values)\n",
    "    wide_df.columns= list(map('_'.join, [col[::-1] for col in old_cols]))\n",
    "    #wide_df.columns = list(map('_'.join, wide_df.columns.values))\n",
    "    wide_df = wide_df.reset_index()\n",
    "    return wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_unpeel(df_name):\n",
    "    \"\"\"Run unpeel function on tables that have a class column.\"\"\"\n",
    "    df = table_dict[df_name].copy()\n",
    "    \n",
    "    # Get rid of categorical columns\n",
    "    for col in df:\n",
    "        if 'category' in df[col].dtype.name:\n",
    "            df[col] = df[col].astype('string')\n",
    "\n",
    "    # Only unpeel if there is a class column.\n",
    "    class_names = [col for col in df if 'class' in col]\n",
    "    if len(class_names) > 0:\n",
    "        wide_df = unpeel(df, df_name, class_names[0])\n",
    "    else:\n",
    "        wide_df = df\n",
    "    \n",
    "    return wide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupby_utils(df, df_name, util_cols):\n",
    "    \"\"\"Group EIA861 tables at the utility-level\n",
    "    \n",
    "    Some of the qualitative columns may present an aggregation challenge when\n",
    "    grouping at the utility level (nerc_region and ba_code, specifically). To\n",
    "    account for all of these values we'll first look to see if there are any\n",
    "    instances where there are duplicate values (same utility/state/year, diff\n",
    "    nerc region or ba code). If there are, we'll combine them into a single row\n",
    "    EX: SERC and MISC to SERC, MISC. We single out the rows that have duplicates\n",
    "    rather than running this on the whole dataframe to save time.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Set N/A state values to UNK to prevent issues in the .transform() func\n",
    "    df['state'] = df['state'].fillna('UNK')\n",
    "    df = df.set_index(util_cols)\n",
    "    \n",
    "    # Separate the df columns into dtypes\n",
    "    num_df = df.select_dtypes(include=['int64', 'float']).reset_index()\n",
    "    qual_df = df.select_dtypes(exclude=['int64', 'float']).reset_index()\n",
    "    \n",
    "    # See whether any of the columns are duplicated at the utility-state-date level\n",
    "    qual_df['dup'] = qual_df.duplicated(subset=util_cols, keep=False)\n",
    "    \n",
    "    # Divide into duplicated and non-duplicated\n",
    "    dup_df = qual_df[qual_df['dup']==True]\n",
    "    non_dup_df = qual_df[qual_df['dup']==False]\n",
    "    \n",
    "    if dup_df.empty:\n",
    "        logger.info(f'{df_name} has no duplicates')\n",
    "        return df.reset_index()\n",
    "    else:\n",
    "        logger.info(f'{df_name}')\n",
    "        # Combine those that are duplicated into VAL1, VAL2 units\n",
    "        dup_transformed = dup_df.groupby(util_cols).transform(lambda x: ' ,'.join(x.unique()))\n",
    "        dup_grouped = (\n",
    "            dup_df[util_cols]\n",
    "            .drop_duplicates()\n",
    "            .join(dup_transformed)\n",
    "            .groupby(util_cols)\n",
    "            .first()\n",
    "            .reset_index()\n",
    "        )\n",
    "        # Grab the first value for non-duplicated values\n",
    "        non_dup_grouped = non_dup_df.groupby(util_cols).first().reset_index()\n",
    "\n",
    "        # Combine newly grouped duplicates and non duplicates\n",
    "        qual_grouped = dup_grouped.append(non_dup_grouped, ignore_index=True)\n",
    "\n",
    "        # Sum numeric columns\n",
    "        num_grouped = num_df.groupby(util_cols).sum(min_count=1)\n",
    "\n",
    "        # Merge numeric and qualitative dataframes back together\n",
    "        merge_df = pd.merge(num_grouped, qual_grouped, on=util_cols).drop('dup', axis=1)\n",
    "        \n",
    "        return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mega_merge(table_dict):\n",
    "    \"\"\"Merge all the EIA 861 tables together\"\"\"\n",
    "    # Get the list of eia861 tables and merge them together. Add numeric suffixes to columns that repeat.\n",
    "    #table_list = list(table_dict.values())\n",
    "    merge_df = pd.DataFrame(columns=util_cols)\n",
    "    #num = 0\n",
    "    for df_name, df in table_dict.items():\n",
    "        logger.info(f'merging {df_name}')\n",
    "        moniker = moniker_dict[df_name]\n",
    "        df = df.set_index(util_cols)\n",
    "        df.columns = df.columns.map(lambda x: str(x) + f'_{moniker}_')\n",
    "        merge_df = pd.merge(merge_df, df, on=util_cols, how='outer')\n",
    "        #num = num+1\n",
    "    \n",
    "    return merge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpeel_group_merge():\n",
    "    \"\"\"Re-widen all tables, groupby utility, merge into one mega table.\"\"\"\n",
    "    # Go through list of tables and widen. Use unpeel_list because \n",
    "    # the non/net_metering tables have to be run twice.\n",
    "    for df_name in unpeel_list:\n",
    "        wide_df = check_and_unpeel(df_name)\n",
    "        table_dict[df_name] = wide_df\n",
    "    \n",
    "    # Group each of the widened tables by utility/state/date\n",
    "    for df_name, df in table_dict.items():\n",
    "        wide_df = df.copy()\n",
    "        util_df = groupby_utils(wide_df, df_name, util_cols)\n",
    "        table_dict[df_name] = util_df\n",
    "        \n",
    "    # Merge wide, grouped tables together into one \"mega\" dataframe\n",
    "    mega_df = mega_merge(table_dict)\n",
    "    \n",
    "    return mega_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_common_cols(df, col_name):\n",
    "    \"\"\"Turn repeat columns into one column with all values.\"\"\"\n",
    "    col_list = [col for col in df if col_name in col]\n",
    "    col_df = df.set_index(util_cols)[col_list]\n",
    "    temp_df = col_df.fillna('UNK')\n",
    "    temp_df = temp_df.eq(temp_df.iloc[:, 0], axis=0)\n",
    "    col_df['bool'] = temp_df.eq(temp_df.iloc[:, 0], axis=0).all(1)\n",
    "    col_df_false = col_df[col_df['bool']==False].copy()\n",
    "    col_df_false = col_df_false.astype('object')\n",
    "    col_df_false.fillna(np.nan)\n",
    "    col_df_false[col_name] = (\n",
    "        col_df_false[col_df_false.columns[:-1]]\n",
    "        .apply(lambda x: ', '.join(x.dropna().unique()), axis=1)\n",
    "    )\n",
    "    df = df.drop(col_list, axis=1)\n",
    "    df = pd.merge(df, col_df_false[[col_name]], on=util_cols, how='outer')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_over_common_cols(mega_df):\n",
    "    \n",
    "    common_cols = [\n",
    "        'balancing_authority_code_eia',\n",
    "        'utility_name_eia',\n",
    "        'nerc_region',\n",
    "        'entity_type',\n",
    "    ]\n",
    "    # get rid of short form cols\n",
    "    logger.info('removing short form columns')\n",
    "    drop_list = []\n",
    "    for col in mega_df:\n",
    "        if 'short_form' in col:\n",
    "            drop_list.append(col)\n",
    "    mega_df = mega_df.drop(drop_list, axis=1)\n",
    "            \n",
    "    # Compare duplicate columns in the mega table\n",
    "    for col in common_cols:\n",
    "        logger.info(f'comparing column values for {col}')\n",
    "        mega_df = compare_common_cols(mega_df, col)\n",
    "    \n",
    "    return mega_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mega_df = unpeel_group_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = loop_over_common_cols(mega_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_excel('/Users/aesharpe/Desktop/mega_eia861.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_val_dict = {\n",
    "    '_AMI_': ['advanced_metering_infrastructure_eia861', []],\n",
    "    '_DG_': ['distributed_generation_eia861', ['capacity_mw']],\n",
    "    '_DP_': ['dynamic_pricing_eia861', []],\n",
    "    '_DR_': ['demand_response_eia861', ['cost']],\n",
    "    '_DS_': ['distribution_systems_eia861', []],\n",
    "    '_DSM_': ['demand_side_management_eia861', ['cost', 'payment']],\n",
    "    '_EE_': ['energy_efficiency_eia861', []],\n",
    "    '_GP_': ['green_pricing_eia861', []],\n",
    "    '_M_': ['mergers_eia861', []],\n",
    "    '_NM_': ['net_metering_eia861', []],\n",
    "    '_NNM_': ['non_net_metering_eia861', []],\n",
    "    '_OD_': ['operational_data_eia861', []],\n",
    "    '_R_': ['reliability_eia861', []],\n",
    "    '_S_': ['sales_eia861', []],\n",
    "    '_ST_': ['service_territory_eia861', []],\n",
    "    '_UD_': ['utility_data_eia861', []],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = val_df.set_index(util_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split mega data into OG eia table chunks in prep for comparison \n",
    "monikers = list(d_val_dict.keys())#list(set(moniker_dict.values()))\n",
    "monikers.sort()\n",
    "\n",
    "by_eia_table_dict = {}\n",
    "for moniker in monikers:\n",
    "    moniker_cols = [col for col in val_df if moniker in col]\n",
    "    non_moniker_cols = [col.strip(f'_{moniker}_') for col in moniker_cols]\n",
    "    moniker_df = val_df[moniker_cols]\n",
    "    moniker_df.columns = non_moniker_cols\n",
    "    by_eia_table_dict[moniker] = moniker_df.reset_index()\n",
    "    \n",
    "# delete cols with only null values -- if you uncomment this, then there will be some\n",
    "# cases where a reported column also has all nulls (as opposed to made up cols from the\n",
    "# re-widening process)\n",
    "for name, table in by_eia_table_dict.items():\n",
    "    null_cols = []\n",
    "    for col in table:\n",
    "        if table[col].dtype == 'float' or table[col].dtype == 'int':\n",
    "            if table[col].isnull().all():\n",
    "                null_cols.append(col)\n",
    "    by_eia_table_dict[name] = table.drop(null_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prep raw data for comparison\n",
    "raw_dfs_dict = eia861_raw_dfs.copy()\n",
    "\n",
    "for df_name, df in raw_dfs_dict.items():\n",
    "    df = pudl.helpers.fix_eia_na(df)\n",
    "    df = pudl.helpers.convert_to_date(df)\n",
    "    raw_dfs_dict[df_name] = df\n",
    "    \n",
    "raw_dfs_dict = pudl.helpers.convert_dfs_dict_dtypes(raw_dfs_dict, 'eia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = raw_dfs_dict['operational_data_eia861'].copy()\n",
    "test2 = test[test['utility_id_eia'].isna()]\n",
    "test2.to_excel('OD_NA.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse order of customer_class and tech_class in raw net/non_net metering tables\n",
    "\n",
    "tc = pudl.constants.TECH_CLASSES\n",
    "cc = pudl.constants.CUSTOMER_CLASSES\n",
    "\n",
    "def swap_col_order(df_name):\n",
    "    raw_order_cols = raw_dfs_dict[df_name].columns.tolist()\n",
    "    #test = ['commercial_chp_cogen_customers', '']\n",
    "    new_order_cols = []\n",
    "    for col in raw_order_cols:\n",
    "        for c in cc: \n",
    "            if c in col:\n",
    "                for t in tc:\n",
    "                    if t in col:\n",
    "                        col = col.replace(f'{c}_{t}_', f'{t}_{c}_')\n",
    "        new_order_cols.append(col)\n",
    "        \n",
    "    raw_dfs_dict[df_name].columns = new_order_cols\n",
    "\n",
    "swap_col_order('net_metering_eia861')\n",
    "swap_col_order('non_net_metering_eia861')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt raw tables to account for data cleaning and manipulation\n",
    "\n",
    "dr_df = raw_dfs_dict['demand_response_eia861'].copy()\n",
    "raw_dfs_dict['demand_response_eia861'] = (\n",
    "    dr_df.drop_duplicates(subset=util_cols+['balancing_authority_code_eia'])\n",
    ")\n",
    "dsm_df = raw_dfs_dict['demand_side_management_eia861'].copy()\n",
    "raw_dfs_dict['demand_side_management_eia861'] = (\n",
    "    dsm_df.loc[dsm_df['utility_id_eia'] != 88888].copy()\n",
    ")\n",
    "nm_df = raw_dfs_dict['net_metering_eia861'].copy()\n",
    "raw_dfs_dict['net_metering_eia861'] = (\n",
    "    nm_df.loc[nm_df['utility_id_eia'] != 99999].copy()\n",
    ")\n",
    "nnm_df = raw_dfs_dict['non_net_metering_eia861'].copy()\n",
    "raw_dfs_dict['non_net_metering_eia861'] = (\n",
    "    nnm_df.loc[nnm_df['utility_id_eia'] != 99999].copy()\n",
    ")\n",
    "od_df = raw_dfs_dict['operational_data_eia861'].copy()\n",
    "raw_dfs_dict['operational_data_eia861'] = (\n",
    "    od_df.loc[od_df['utility_id_eia'] != 88888].copy()\n",
    ") #NULLS!\n",
    "r_df = raw_dfs_dict['reliability_eia861'].copy()\n",
    "raw_dfs_dict['reliability_eia861'] = (\n",
    "    r_df.drop_duplicates(subset=util_cols)\n",
    ")\n",
    "s_df = raw_dfs_dict['sales_eia861'].copy()\n",
    "raw_dfs_dict['sales_eia861'] = (\n",
    "    s_df.drop_duplicates(subset=util_cols + ['balancing_authority_code_eia'])\n",
    ")\n",
    "s_df = raw_dfs_dict['sales_eia861'].copy()\n",
    "raw_dfs_dict['sales_eia861'] = (\n",
    "    s_df.loc[s_df['utility_id_eia'] != 88888].copy()\n",
    ")\n",
    "s_df = raw_dfs_dict['sales_eia861'].copy()\n",
    "raw_dfs_dict['sales_eia861'] = (\n",
    "    s_df.loc[s_df['utility_id_eia'] != 99999].copy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHY IS THIS BLANK AFTER RUNNING THE ABOVE??????? \n",
    "test = raw_dfs_dict['operational_data_eia861'].copy()\n",
    "test['utility_id_eia'] = test.utility_id_eia.astype('float')\n",
    "#test.loc[test['utility_id_eia'].isna()]\n",
    "#test[['utility_id_eia']].sort_values('utility_id_eia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_against_raw_numeric(df, raw_df, df_name_and_exceptions):\n",
    "    \"\"\"Compare numeric columns against their raw counterpart data.\"\"\"\n",
    "    logger.info('')\n",
    "    logger.info(f'checking columns for {df_name_and_exceptions[0]} table')\n",
    "    \n",
    "    num_df = df.select_dtypes(include=['int64', 'float']).set_index('utility_id_eia')\n",
    "    raw_num_df = raw_df.select_dtypes(include=['int64', 'float']).set_index('utility_id_eia')\n",
    "    \n",
    "    not_in_raw = [col for col in num_df if col not in raw_num_df]\n",
    "    not_in_transformed = [col for col in raw_num_df if col not in num_df]\n",
    "    not_in_transformed = [col for col in not_in_transformed if 'total' not in col] #exclude total cols\n",
    "    in_both = [col for col in num_df if col in raw_num_df]\n",
    "    for exception in df_name_and_exceptions[1]:\n",
    "        in_both = [col for col in in_both if exception not in col]\n",
    "    \n",
    "    logger.info(f'     columns not in the raw_df: {not_in_raw}')\n",
    "    logger.info(f'     columns not in the transformed_df {not_in_transformed}')\n",
    "    \n",
    "    # Check whether the raw column total is the same as the transformed column total\n",
    "    for col in in_both:\n",
    "        new_sum = round(num_df[col].sum(skipna=True), 0)\n",
    "        raw_sum = round(raw_num_df[col].sum(skipna=True), 0)\n",
    "        if new_sum != raw_sum:\n",
    "            if raw_sum != round((new_sum/1000), 0):\n",
    "                print(f'     sum miss-match for col: {col}')\n",
    "                print(f'     new_sum: {new_sum}, raw_sum: {raw_sum}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for moniker, df_name_and_exceptions in d_val_dict.items():\n",
    "    check_against_raw_numeric(\n",
    "        by_eia_table_dict[moniker],\n",
    "        raw_dfs_dict[df_name_and_exceptions[0]],\n",
    "        df_name_and_exceptions\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of data transformations:\n",
    "\n",
    "**DG**: change pct into mw - sums will differ\n",
    "\n",
    "**DR**: cost cols thousands to ones, drop duplicates\n",
    "\n",
    "**DSM**: cost / payment cols thousands to one, removed 88888 utilities\n",
    "\n",
    "**NM**: removed 99999 utilities, extra colums from reconstruction that are all nan. can delete but don't impact sum.\n",
    "\n",
    "**NNM**: removed 99999 utilitiesremoved 99999 utilities, *had to fix issue with capacity_mw merge deleting y vs. x*\n",
    "\n",
    "**OD**: removed 88888 utilities, **removed utilities with NA for eia_id**\n",
    "\n",
    "**R**: dropped duplicates\n",
    "\n",
    "**S**: removed 99999 and 88888 utilities, dropped duplicates, revenue cols thousands to one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = raw_dfs_dict['operational_data_eia861']\n",
    "test = test.reset_index()\n",
    "test[test['utility_id_eia'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Other Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all of the data is loaded and looks like it's in good shape, do any initial wrangling that's specific to this particular analysis. This should mostly make use of the higher level functions which were defined above. If this step takes a while, don't be shy about producing `logging` outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = eia_transformed_dfs['demand_side_management_misc_eia861']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['dup'] = test.duplicated(subset=['utility_id_eia', 'state', 'report_date'])\n",
    "test.sort_values('dup', ascending=False)\n",
    "\n",
    "print(len(test.groupby(['utility_id_eia', 'state', 'report_date'])))\n",
    "print(len(test.groupby(['utility_id_eia', 'state', 'report_date', 'nerc_region'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation Test with Pandera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zscore not a good measure because utilities are not all uniform in size.\n",
    "\n",
    "df = eia_transformed_dfs['advanced_metering_infrastructure_eia861'].copy()\n",
    "df['advanced_metering_infrastructure'] = df['advanced_metering_infrastructure'].fillna(0)\n",
    "df['automated_meter_reading'] = df['automated_meter_reading'].fillna(0)\n",
    "df['non_amr_ami'] = df['non_amr_ami'].fillna(0)\n",
    "df['total_meters'] = df['total_meters'].fillna(0)\n",
    "\n",
    "df = df.assign(\n",
    "    summ=lambda x: (\n",
    "        x.advanced_metering_infrastructure \n",
    "        + x.automated_meter_reading \n",
    "        + x.non_amr_ami),\n",
    "    same=lambda x: x.summ == x.total_meters\n",
    ")\n",
    "\n",
    "df[(df['same']==False) & (df['total_meters']!= 0)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
