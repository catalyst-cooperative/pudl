{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dagster import AssetKey\n",
    "from pudl.etl import defs\n",
    "import pandas as pd\n",
    "from pudl.helpers import zero_pad_numeric_string, organize_cols, standardize_phone_column, fix_na, analyze_missing_values, standardize_state_columns\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No dagster instance configuration file (dagster.yaml) found at /Users/sam/Documents/pudl-data/dagster_home. Defaulting to loading and storing all metadata with /Users/sam/Documents/pudl-data/dagster_home. If this is the desired behavior, create an empty dagster.yaml file in /Users/sam/Documents/pudl-data/dagster_home.\n",
      "2024-10-11 17:22:13 -0400 - dagster - DEBUG - system - Loading file from: /Users/sam/Documents/pudl-data/dagster_home/storage/raw_phmsagas__yearly_distribution using PickledObjectFilesystemIOManager...\n"
     ]
    }
   ],
   "source": [
    "raw_df = defs.load_asset_value(AssetKey(\"raw_phmsagas__yearly_distribution\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## core_phmsagas__yearly_distribution_operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df[[\n",
    "    \"report_date\",\n",
    "    \"report_number\",\n",
    "    \"report_submission_type\",\n",
    "    \"report_year\",\n",
    "    \"operator_id_phmsa\",\n",
    "    \"operator_name_phmsa\",\n",
    "    \"office_address_street\",\n",
    "    \"office_address_city\",\n",
    "    \"office_address_state\",\n",
    "    \"office_address_zip\",\n",
    "    \"office_address_county\",\n",
    "    \"excavation_damage_excavation_practices\",\n",
    "    \"excavation_damage_locating_practices\",\n",
    "    \"excavation_damage_one_call_notification\",\n",
    "    \"excavation_damage_other\",\n",
    "    \"excavation_damage_total\",\n",
    "    \"excavation_tickets\",\n",
    "    \"services_efv_in_system\",\n",
    "    \"services_efv_installed\",\n",
    "    \"services_shutoff_valve_in_system\",\n",
    "    \"services_shutoff_valve_installed\",\n",
    "    \"federal_land_leaks_repaired_or_scheduled\",\n",
    "    \"percent_unaccounted_for_gas\",\n",
    "    \"additional_information\",\n",
    "    \"preparer_email\",\n",
    "    \"preparer_fax\",\n",
    "    \"preparer_name\",\n",
    "    \"preparer_phone\",\n",
    "    \"preparer_title\",\n",
    "    # Adding these fields temporarily for transformation cleanup\n",
    "    \"headquarters_address_city\",\n",
    "    \"headquarters_address_county\",\n",
    "    \"headquarters_address_state\",\n",
    "    \"headquarters_address_street\",\n",
    "    \"headquarters_address_zip\"\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to ints\n",
    "# Would have included \"federal_land_leaks_repaired_or_scheduled\" in this list but there were a couple rows with decimal values\n",
    "columns_to_convert = [\n",
    "    \"report_year\",\n",
    "    \"report_number\",\n",
    "    \"operator_id_phmsa\",\n",
    "    \"excavation_damage_excavation_practices\",\n",
    "    \"excavation_damage_locating_practices\",\n",
    "    \"excavation_damage_one_call_notification\",\n",
    "    \"excavation_damage_other\",\n",
    "    \"excavation_damage_total\",\n",
    "    \"excavation_tickets\",\n",
    "    \"services_efv_in_system\",\n",
    "    \"services_efv_installed\",\n",
    "    \"services_shutoff_valve_in_system\",\n",
    "    \"services_shutoff_valve_installed\"\n",
    "]\n",
    "df[columns_to_convert] = df[columns_to_convert].astype(\"Int64\")\n",
    "\n",
    "# Ensure all \"report_year\" values have four digits\n",
    "mask = df[\"report_year\"] < 100\n",
    "\n",
    "# Convert 2-digit years to appropriate 4-digit format (assume cutoff at year 50)\n",
    "# We could also use the first 4 digits of the \"report_number\" but there was at least one anomaly here with an invalid year\n",
    "df.loc[mask, \"report_year\"] = df.loc[mask, \"report_year\"].apply(\n",
    "    lambda x: 2000 + x if x < 50 else 1900 + x\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operator Table Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA values with zeroes because these columns are simply counts.\n",
    "# Note that \"excavation_damage...\" columns should sum up to the value in \"excavation_damage_total\". However, many rows\n",
    "# (on the scale of thousands) do not actually sum up to \"excavation_damage_total\".\n",
    "columns_to_fill = [\n",
    "    \"excavation_damage_excavation_practices\",\n",
    "    \"excavation_damage_locating_practices\",\n",
    "    \"excavation_damage_one_call_notification\",\n",
    "    \"excavation_damage_other\",\n",
    "    \"excavation_damage_total\",\n",
    "    \"excavation_tickets\",\n",
    "    \"services_efv_in_system\",\n",
    "    \"services_efv_installed\",\n",
    "    \"services_shutoff_valve_in_system\",\n",
    "    \"services_shutoff_valve_installed\",\n",
    "    \"federal_land_leaks_repaired_or_scheduled\"\n",
    "]\n",
    "df[columns_to_fill] = df[columns_to_fill].fillna(0)\n",
    "\n",
    "# Fill in bad strings\n",
    "df = fix_na(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize case for city, county, operator name, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capitalize the first letter of each word in all object-type columns except the excluded ones\n",
    "exclude_columns = ['headquarters_address_state', 'office_address_state']\n",
    "df[df.select_dtypes(include=['object']).columns.difference(exclude_columns)] = \\\n",
    "    df[df.select_dtypes(include=['object']).columns.difference(exclude_columns)].apply(lambda col: col.str.title())\n",
    "\n",
    "# List of state columns to standardize\n",
    "state_columns_to_standardize = ['headquarters_address_state', 'office_address_state']\n",
    "df = standardize_state_columns(df, state_columns_to_standardize)\n",
    "\n",
    "# Trim all the object-type columns\n",
    "df[df.select_dtypes(include=['object']).columns] = df.select_dtypes(include=['object']).applymap(lambda x: x.strip() if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize usage of office vs HQ address over time\n",
    "\n",
    "- Make sure to use \"clean_eia_counties\" from helpers at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up office zip codes\n",
    "df[\"office_address_zip_clean\"] = zero_pad_numeric_string(df[\"office_address_zip\"], 5).astype(\"object\")\n",
    "df[\"headquarters_address_zip_clean\"] = zero_pad_numeric_string(df[\"headquarters_address_zip\"], 5).astype(\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an address DF\n",
    "address_cols = [\n",
    "    'operator_id_phmsa', 'report_year',\n",
    "    'office_address_street', 'office_address_city', 'office_address_state', 'office_address_zip', 'office_address_zip_clean',\n",
    "    'headquarters_address_street', 'headquarters_address_city', 'headquarters_address_state', 'headquarters_address_zip', 'headquarters_address_zip_clean'\n",
    "]\n",
    "\n",
    "df_addresses = df[address_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a concatenated address string for office address\n",
    "df_addresses['office_address'] = df_addresses['office_address_street'].astype(str) + ', ' + \\\n",
    "                                 df_addresses['office_address_city'].astype(str) + ', ' + \\\n",
    "                                 df_addresses['office_address_state'].astype(str) + ' ' + \\\n",
    "                                 df_addresses['office_address_zip_clean'].astype(str)\n",
    "\n",
    "# Create a concatenated address string for headquarters address\n",
    "df_addresses['headquarters_address'] = df_addresses['headquarters_address_street'].astype(str) + ', ' + \\\n",
    "                                       df_addresses['headquarters_address_city'].astype(str) + ', ' + \\\n",
    "                                       df_addresses['headquarters_address_state'].astype(str) + ' ' + \\\n",
    "                                       df_addresses['headquarters_address_zip_clean'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_address(address: str) -> str:\n",
    "    if pd.isna(address):  # Handle missing addresses\n",
    "        return address\n",
    "    address = address.upper()  # Convert to uppercase\n",
    "    address = address.replace('P O BOX', 'PO BOX')  # Standardize \"P O BOX\"\n",
    "    address = address.replace('ST.', 'STREET').replace('RD.', 'ROAD')  # Example replacements\n",
    "    address = address.replace(',', '')  # Remove commas for consistent comparison\n",
    "    address = re.sub(r'\\s+', ' ', address).strip()  # Replace multiple spaces with a single space and trim\n",
    "    return address\n",
    "\n",
    "# Step 4: Apply the standardization to the concatenated addresses\n",
    "df_addresses['office_address_std'] = df_addresses['office_address'].apply(standardize_address)\n",
    "df_addresses['headquarters_address_std'] = df_addresses['headquarters_address'].apply(standardize_address)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_addresses = df_addresses.groupby('operator_id_phmsa').agg(\n",
    "    unique_office_addresses=('office_address', 'nunique'),\n",
    "    unique_headquarters_addresses=('headquarters_address', 'nunique')\n",
    ").reset_index()\n",
    "\n",
    "df_unique_addresses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_addresses[df_unique_addresses.unique_headquarters_addresses>df_unique_addresses.unique_office_addresses].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_addresses[df_unique_addresses.unique_headquarters_addresses>df_unique_addresses.unique_office_addresses].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addresses[df_addresses.operator_id_phmsa == 728][\"headquarters_address\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_addresses[df_addresses.operator_id_phmsa == 728][\"office_address\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily increase the max column width to display full content\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Now print the desired values\n",
    "print(df_addresses[df_addresses.operator_id_phmsa == 728][[\"headquarters_address\"]])\n",
    "\n",
    "# Reset the column width option if needed\n",
    "pd.reset_option('display.max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by operator and sort by year\n",
    "# df_addresses = df_addresses.sort_values(by=['operator_id_phmsa', 'report_year'])\n",
    "\n",
    "# # Create flags for overlap or switch\n",
    "# df_addresses['address_overlap'] = df_addresses['office_address'] == df_addresses['headquarters_address']\n",
    "# df_addresses['address_switch'] = df_addresses.groupby('operator_id_phmsa').apply(\n",
    "#     lambda x: (x['office_address'].shift() == x['headquarters_address']) & \n",
    "#               (x['headquarters_address'].shift() == x['office_address'])\n",
    "# ).reset_index(drop=True)\n",
    "\n",
    "# # Display the results where overlap or switch occurred\n",
    "# df_overlap_switch = df_addresses[(df_addresses['address_overlap'] == True) | (df_addresses['address_switch'] == True)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize telephone and fax number format and drop (000)-000-0000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = standardize_phone_column(df, \"preparer_phone\")\n",
    "# df[df.preparer_phone.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.preparer_fax.notnull()]['report_year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[~df['preparer_fax'].str.contains('@', na=False)]['preparer_fax'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pudl-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
