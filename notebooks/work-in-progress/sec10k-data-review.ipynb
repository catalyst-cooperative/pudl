{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Notebook Preamble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IPython Magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Notebook Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd Party Imports:\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import matplotx\n",
    "import duckdb\n",
    "import polars as pl\n",
    "import sqlalchemy as sa\n",
    "import dagster as dg\n",
    "from dagster import AssetKey\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PUDL Imports\n",
    "import pudl\n",
    "from pudl.etl import defs\n",
    "from pudl.workspace.setup import PudlPaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pudl.logging_helpers.get_logger(\"pudl\")\n",
    "os.environ[\"PUDL_INPUT\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "matplotlib.rcParams[\"figure.dpi\"] = 150\n",
    "matplotlib.style.use(matplotx.styles.onedark)\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.max_rows\", 300)\n",
    "pd.set_option(\"display.max_colwidth\", 1000)\n",
    "\n",
    "pl.Config.set_tbl_rows(100)\n",
    "pl.Config.set_tbl_cols(100)\n",
    "pl.Config.set_fmt_str_lengths(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data access shortcuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pudl.helpers import get_parquet_table as get_parquet\n",
    "import geopandas as gpd\n",
    "\n",
    "def get_asset(table: str) -> pd.DataFrame | gpd.GeoDataFrame:\n",
    "    return defs.load_asset_value(AssetKey(table))\n",
    "\n",
    "def get_pandas(table: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(\n",
    "        Path(os.environ[\"PUDL_OUTPUT\"]) / f\"parquet/{table}.parquet\",\n",
    "        memory_map=True,\n",
    "        engine=\"pyarrow\",\n",
    "    ).convert_dtypes()\n",
    "\n",
    "def get_polars(table: str) -> pl.DataFrame:\n",
    "    return pl.read_parquet(\n",
    "        Path(os.environ[\"PUDL_OUTPUT\"]) / f\"parquet/{table}.parquet\",\n",
    "    )\n",
    "\n",
    "def get_pyarrow(table: str) -> pd.DataFrame:\n",
    "    return pd.read_parquet(\n",
    "        Path(os.environ[\"PUDL_OUTPUT\"]) / f\"parquet/{table}.parquet\",\n",
    "        dtype_backend=\"pyarrow\",\n",
    "        memory_map=True,\n",
    "        engine=\"pyarrow\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = get_polars(\"out_sec10k__quarterly_company_information\")\n",
    "filings = get_polars(\"out_sec10k__quarterly_filings\")\n",
    "parsubs = get_polars(\"out_sec10k__parents_and_subsidiaries\")\n",
    "name_changes = get_polars(\"out_sec10k__changelog_company_name\")\n",
    "ex21 = get_polars(\"core_sec10k__quarterly_exhibit_21_company_ownership\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What fraction of electricity companies are linked to EIA utilities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify industry IDs with lots of Utility ID associations\n",
    "- This is kind of begging the question, but it's not a terrible way to find interesting SICs to look at.\n",
    "- Unsurprisingly the two top SICs with the largest number of Utility ID associations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_sics = (\n",
    "    get_polars(\"out_sec10k__quarterly_company_information\")\n",
    "    .group_by(sic=pl.col(\"industry_id_sic\"))\n",
    "    .agg(\n",
    "        fraction_with_utility_id=pl.col(\"utility_id_eia\").is_not_null().mean()\n",
    "    )\n",
    "    .sort(\"fraction_with_utility_id\", descending=True)\n",
    "    .filter(pl.col(\"fraction_with_utility_id\") > 0.50)\n",
    "    .select(\"sic\").to_series().to_list()\n",
    ")\n",
    "electricity_sics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    get_polars(\"out_sec10k__quarterly_company_information\")\n",
    "    .filter(pl.col(\"industry_id_sic\").is_in(electricity_sics))\n",
    "    .select([\"industry_id_sic\", \"industry_name_sic\"])\n",
    "    .unique([\"industry_id_sic\", \"industry_name_sic\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_ids_by_year = get_polars(\"out_sec10k__quarterly_company_information\").filter(\n",
    "    pl.col(\"industry_id_sic\").is_in(electricity_sics),\n",
    ").with_columns(\n",
    "    year=pl.col(\"report_date\").dt.year()\n",
    ").group_by([\"year\", \"industry_id_sic\"]).agg(\n",
    "    fraction_with_utility_id=pl.col(\"utility_id_eia\").is_not_null().mean(),\n",
    ").sort(\"year\")\n",
    "\n",
    "for sic in util_ids_by_year[\"industry_id_sic\"].unique():\n",
    "    df = util_ids_by_year.filter(pl.col(\"industry_id_sic\") == sic)\n",
    "    plt.plot(df[\"year\"], df[\"fraction_with_utility_id\"], label=sic)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmatched_companies = (\n",
    "    get_polars(\"out_sec10k__quarterly_company_information\")\n",
    "    .filter(\n",
    "        pl.col(\"industry_id_sic\").is_in([\"4911\", \"4931\"]),\n",
    "        pl.col(\"utility_id_eia\").is_not_null(),\n",
    "    )\n",
    "    .select([\"company_name\", \"utility_name_eia\", \"report_date\"])\n",
    "    .unique([\"company_name\", \"utility_name_eia\", \"report_date\"])\n",
    ")\n",
    "unmatched_companies.sample(30).sort(\"report_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    get_polars(\"out_sec10k__parents_and_subsidiaries\")[\n",
    "        \"report_date\",\n",
    "        \"parent_company_central_index_key\",\n",
    "        \"parent_company_utility_id_eia\",\n",
    "        \"parent_company_name\",\n",
    "        \"subsidiary_company_id_sec10k\",\n",
    "        \"subsidiary_company_central_index_key\",\n",
    "        \"subsidiary_company_utility_id_eia\",\n",
    "        \"subsidiary_company_name\",\n",
    "        \"fraction_owned\",\n",
    "    ].filter(\n",
    "        pl.col(\"report_date\").dt.year().is_in([2001, 2023]),\n",
    "        pl.col(\"parent_company_central_index_key\").eq(\"0000072903\")\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electricity_sics = [\"4911\", \"4931\"]\n",
    "sics = [\"4911\", \"4931\", \"6798\", \"6189\", \"1311\", \"2621\", \"2834\", \"4991\", \"4922\", \"4961\", \"2631\", \"7372\", \"4924\", \"3674\", \"2911\"]\n",
    "companies.filter(\n",
    "    pl.col(\"utility_id_eia\").is_not_null(),\n",
    "    pl.col(\"industry_id_sic\").is_in(sics)\n",
    ").group_by([\"industry_name_sic\"]).len().sort(\"len\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies.filter(\n",
    "    # pl.col(\"utility_id_eia\").is_not_null(),\n",
    "    pl.col(\"industry_name_sic\").str.contains(\".*(electricity|power).*\")\n",
    ").select([\"industry_name_sic\", \"industry_id_sic\"]).group_by(\"industry_id_sic\").len().sort(\"len\", descending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nullness_by_year(\n",
    "    df: pd.DataFrame,\n",
    "    title: str = \"Fraction of Non-Null Values by Column-Year\",\n",
    "):\n",
    "    \"\"\"Plot the fraction of null values in a dataframe by column-year.\n",
    "\n",
    "    Creates a binary visualization where zeros (completely missing data) are\n",
    "    displayed in black and any non-zero values (some data present) are\n",
    "    displayed in white.\n",
    "\n",
    "    The x-axis represents the years, and the y-axis represents the columns.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame with columns as features and rows as years.\n",
    "        title: Title for the plot.\n",
    "    \"\"\"\n",
    "    import matplotlib.colors as mcolors\n",
    "    import numpy as np\n",
    "\n",
    "    # Calculate dynamic height based on number of rows (columns in the data)\n",
    "    # Use a minimum height of 4 inches and scale with 0.15 inches per row\n",
    "    min_height = 4\n",
    "    height_per_row = 0.15\n",
    "    dynamic_height = max(min_height, len(df.index) * height_per_row)\n",
    "\n",
    "    # Create the plot with dynamic sizing\n",
    "    fig, ax = plt.subplots(figsize=(10, dynamic_height))\n",
    "\n",
    "    # Create binary data: 0 for zeros, 1 for non-zeros\n",
    "    binary_data = (df.values > 0).astype(int)\n",
    "\n",
    "    # Create binary colormap: black for 0, white for 1\n",
    "    colors = ['black', 'white']\n",
    "    binary_cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    # Create the heatmap using imshow\n",
    "    im = ax.imshow(\n",
    "        binary_data,\n",
    "        cmap=binary_cmap,\n",
    "        aspect='auto',\n",
    "        vmin=0,\n",
    "        vmax=1,\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "\n",
    "    # Add grid lines for cell borders\n",
    "    # Vertical lines (between years)\n",
    "    for i in range(len(df.columns) + 1):\n",
    "        ax.axvline(x=i - 0.5, color='gray', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Horizontal lines (between columns)\n",
    "    for i in range(len(df.index) + 1):\n",
    "        ax.axhline(y=i - 0.5, color='gray', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "    # Set the ticks and labels with smaller fonts\n",
    "    ax.set_xticks(range(len(df.columns)))\n",
    "    ax.set_xticklabels(df.columns, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_yticks(range(len(df.index)))\n",
    "    ax.set_yticklabels(df.index, fontsize=7)\n",
    "\n",
    "    # Labels and title with smaller fonts\n",
    "    ax.set_xlabel('Year', fontsize=10)\n",
    "    ax.set_ylabel('Column', fontsize=10)\n",
    "    ax.set_title(title, fontsize=11)\n",
    "\n",
    "    # Add colorbar with custom labels\n",
    "    cbar = plt.colorbar(im, ax=ax, ticks=[0, 1])\n",
    "    cbar.ax.set_yticklabels(['No Data (0)', 'Some Data (>0)'], fontsize=8)\n",
    "    cbar.set_label('Data Availability', fontsize=9)\n",
    "\n",
    "    # Adjust layout to prevent label cutoff\n",
    "    plt.tight_layout()\n",
    "\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"out_eia__monthly_generators\"\n",
    "parquet_path = PudlPaths().parquet_path(table_name)\n",
    "nullness = calculate_nullness_by_year(\n",
    "    parquet_path,\n",
    "    date_column=\"report_date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_nullness_by_year(\n",
    "    nullness,\n",
    "    title=table_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf = pudl.helpers.get_parquet_table(\"out_eia923__yearly_generation_fuel_by_generator_energy_source_owner\")\n",
    "gf[\"observed_capfac\"] = gf[\"net_generation_mwh\"] / (gf[\"capacity_mw\"] * 8784)\n",
    "inconsistent = gf.query(\"observed_capfac > 1.0\")\n",
    "inconsistent[\"observed_capfac\"].hist(bins=100, range=(0,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent[\"observed_capfac\"].sort_values(ascending=False).tail(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pudl.metadata.classes import Package\n",
    "pudl_pkg = Package.from_resource_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_eia923_resources = [res.name for res in pudl_pkg.resources if \"core_eia923\" in res.name and \"coalmine\" not in res.name]\n",
    "plant_ids = [\n",
    "    set(get_parquet(table, columns=[\"plant_id_eia\"])[\"plant_id_eia\"].unique())\n",
    "    for table in core_eia923_resources\n",
    "]\n",
    "plant_ids = sorted(set.union(*plant_ids))\n",
    "len(plant_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_eia930: pd.DataFrame = get_parquet(\"out_eia930__hourly_operations\")\n",
    "subs_eia930: pd.DataFrame = get_parquet(\"out_eia930__hourly_subregion_demand\")\n",
    "pa_ferc714: pd.DataFrame = get_parquet(\"out_ferc714__hourly_planning_area_demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_eia930.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imputation(df):\n",
    "    reported_na_or_zero = ((df.demand_reported_mwh.isna()) | (df.demand_reported_mwh == 0)).sum()\n",
    "    imputed_na_or_zero = ((df.demand_imputed_pudl_mwh.isna()) | (df.demand_imputed_pudl_mwh == 0)).sum()\n",
    "    total_flagged = df.demand_imputed_pudl_mwh_imputation_code.notna().sum()\n",
    "    print(f\"Flagged for imputation: {total_flagged}\")\n",
    "    print(f\"Reported NA or 0: {reported_na_or_zero}\")\n",
    "    print(f\"Imputed NA or 0: {imputed_na_or_zero}\")\n",
    "    display(df.demand_imputed_pudl_mwh_imputation_code.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_imputation(pa_ferc714)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_ferc714[pa_ferc714.demand_reported_mwh.notna() & (pa_ferc714.demand_imputed_pudl_mwh.isna())].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_base = get_table(\"out_ferc1__yearly_rate_base\")\n",
    "rate_base.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_base.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex21_own = get_table(\"core_sec10k__quarterly_exhibit_21_company_ownership\")\n",
    "ex21_own.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_cols = [\n",
    "    \"operator_id_phmsa\",\n",
    "    \"report_year\",\n",
    "    \"operating_state\",\n",
    "    \"commodity\",\n",
    "]\n",
    "dude = phmsa_ops.set_index(idx_cols).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude[dude.index.duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_filings = get_table(\"raw_sec10k__quarterly_filings\")\n",
    "raw_company_info = get_table(\"raw_sec10k__quarterly_company_information\")\n",
    "raw_ownership = get_table(\"raw_sec10k__exhibit_21_company_ownership\")\n",
    "raw_parsubs = get_table(\"raw_sec10k__parents_and_subsidiaries\")\n",
    "\n",
    "core_filings = get_table(\"core_sec10k__quarterly_filings\")\n",
    "out_filings = get_table(\"out_sec10k__quarterly_filings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpratk_avail_cap = get_table(\"out_gridpathratoolkit__hourly_available_capacity_factor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpratk_avail_cap.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_filings[\"report_date\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pudl.metadata import PUDL_PACKAGE\n",
    "from pudl.workspace.setup import PudlPaths\n",
    "pudl_paths = PudlPaths()\n",
    "md = PUDL_PACKAGE.to_sql()\n",
    "pudl_engine = sa.create_engine(pudl_paths.sqlite_db_uri(\"pudl\"))\n",
    "# md.create_all(pudl_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imputed = pd.read_parquet(\"s3://pudl.catalyst.coop/nightly/out_ferc714__hourly_planning_area_demand.parquet\")\n",
    "old_imputed = pd.read_parquet(\"s3://pudl.catalyst.coop/nightly/_out_ferc714__hourly_imputed_demand.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_imputed = pd.merge(\n",
    "    new_imputed.set_index([\"respondent_id_ferc714\", \"datetime_utc\"]),\n",
    "    old_imputed.set_index([\"respondent_id_ferc714\", \"datetime_utc\"]),\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    suffixes=(\"_new\", \"_old\"),\n",
    "    how=\"outer\",\n",
    ")\n",
    "# Reset the index to make `respondent_id_ferc714` a data column\n",
    "both_imputed = both_imputed.reset_index()\n",
    "both_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Assign a discrete color to each `respondent_id_ferc714`\n",
    "unique_ids = both_imputed[\"respondent_id_ferc714\"].unique()\n",
    "palette = sns.color_palette(\"tab20\", len(unique_ids))\n",
    "color_map = {rid: palette[i] for i, rid in enumerate(unique_ids)}\n",
    "colors = both_imputed[\"respondent_id_ferc714\"].map(color_map)\n",
    "\n",
    "# Create the scatter plot\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.scatter(\n",
    "    both_imputed[\"demand_mwh\"],\n",
    "    both_imputed[\"demand_imputed_pudl_mwh\"],\n",
    "    c=colors,\n",
    "    s=0.1,\n",
    ")\n",
    "\n",
    "# Set both axes to logarithmic scale\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(1e-1, 1e6)\n",
    "plt.ylim(1e-1, 1e6)\n",
    "\n",
    "# Add gridlines\n",
    "plt.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "# Optionally add labels and a title\n",
    "plt.xlabel(\"Old Imputed FERC-714 Planning Area Demand [MWh]\")\n",
    "plt.ylabel(\"New Imputed FERC-714 Planning Area Demand [MWh]\")\n",
    "plt.title(\"Log-Log Scatter Plot of Old vs New Imputed Demand\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sub_eia930 = get_table(\"out_eia930__hourly_subregion_demand\")\n",
    "core_sub_eia930 = get_table(\"core_eia930__hourly_subregion_demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_sub_eia930"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## subregion output EIA-930 notes\n",
    "- There's no EIA imputation for the subregions, but for naming clarity purposes, do we want to rename `demand_imputed_mwh` so that it will be consistent with the names of the PUDL imputed columns that will exist in other tables?\n",
    "- It would be nice if the table were sorted by BA Code, subregion code, and time to ensure contiguous time series.\n",
    "- Looking at `CISO` I see that there are **more** NA values in the imputed column than the reported column. Is that expected? I would have thought we'd fill in the missing values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sub_eia930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = out_sub_eia930.set_index([\"balancing_authority_code_eia\", \"balancing_authority_subregion_code_eia\", \"datetime_utc\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude = (\n",
    "    out_sub_eia930\n",
    "    .groupby(\n",
    "        [\n",
    "            \"balancing_authority_code_eia\",\n",
    "            \"balancing_authority_subregion_code_eia\"\n",
    "        ],\n",
    "        observed=True\n",
    "    )[\n",
    "        [\n",
    "            \"demand_reported_mwh\",\n",
    "            \"demand_imputed_mwh\"\n",
    "        ]\n",
    "    ]\n",
    "    .count()\n",
    "    .assign(\n",
    "        ratio=lambda x: x[\"demand_imputed_mwh\"] / x[\"demand_reported_mwh\"]\n",
    "    )\n",
    ")\n",
    "printme = dude.to_markdown()\n",
    "print(printme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = \"2019-02-01\"\n",
    "end_date = \"2019-02-14\"\n",
    "df.loc[(\"CISO\", \"PGAE\", slice(start_date, end_date)), [\"demand_reported_mwh\", \"demand_imputed_mwh\"]].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core_sec10k__quarterly_company_information(raw_sec10k__quarterly_company_information: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean shit up.\"\"\"\n",
    "    # Strip erroneous \"]\" characters from company information fact names (the keys in\n",
    "    # the key-value pairs). This has to be done before the table is re-shaped.\n",
    "    df = (\n",
    "        raw_sec10k__quarterly_company_information\n",
    "        .assign(\n",
    "            company_information_fact_name=lambda x: x.company_information_fact_name.str.lstrip(\"]\"),\n",
    "            filename_sec10k=lambda x: x.filename_sec10k.str.removeprefix(\"edgar/data/\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    def pivot_info_block(df: pd.DataFrame, block: str) -> pd.DataFrame:\n",
    "        \"\"\"Extract distinct blocks of company information for separate processing.\"\"\"\n",
    "        pivoted = (\n",
    "            df.loc[df.company_information_block == block].pivot(\n",
    "                values=\"company_information_fact_value\",\n",
    "                index=[\n",
    "                    \"filename_sec10k\",\n",
    "                    \"filer_count\",\n",
    "                    \"report_date\",\n",
    "                    \"company_information_block_count\",\n",
    "                ],\n",
    "                columns=\"company_information_fact_name\",\n",
    "            )\n",
    "            .convert_dtypes()\n",
    "        )\n",
    "        pivoted.columns.name = None\n",
    "        return pivoted\n",
    "\n",
    "    business_address = pivot_info_block(df, \"business_address\").rename(columns={\"business_phone\": \"phone\"})\n",
    "    company_data = pivot_info_block(df, \"company_data\").drop(columns=[\"organization_name\"])\n",
    "    filing_values = pivot_info_block(df, \"filing_values\")\n",
    "    mail_address = pivot_info_block(df, \"mail_address\")\n",
    "    former_company = pivot_info_block(df, \"former_company\")\n",
    "\n",
    "    # Add prefixes where needed to ensure that column names are distinct after concatentation.\n",
    "    business_address.columns = [f\"business_{col}\" for col in business_address.columns]\n",
    "    mail_address.columns = [f\"mail_{col}\" for col in mail_address.columns]\n",
    "    return business_address, company_data, filing_values, mail_address, former_company\n",
    "    #return pd.concat([business_address, company_data, filing_values, mail_address], axis=\"columns\").reset_index()\n",
    "\n",
    "    df = raw_sec10k__quarterly_company_information.pivot(\n",
    "        values=\"company_information_fact_value\",\n",
    "        index=[\n",
    "            \"filename_sec10k\",\n",
    "            \"report_date\",\n",
    "            \"company_information_block\",\n",
    "            \"company_information_block_count\",\n",
    "        ],\n",
    "        columns=\"company_information_fact_name\",\n",
    "    )\n",
    "    df.columns.name = None\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_info = get_table(\"core_sec10k__quarterly_company_information\")\n",
    "raw_info = get_table(\"raw_sec10k__quarterly_company_information\")\n",
    "#file_sec10k = get_table(\"core_sec10k__quarterly_filings\")\n",
    "#own_sec10k = get_table(\"core_sec10k__quarterly_exhibit_21_company_ownership\")\n",
    "#out_sec10k = get_table(\"out_sec10k__parents_and_subsidiaries\")\n",
    "#name_change_sec10k = get_table(\"core_sec10k__changelog_company_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_address, company_data, filing_values, mail_address, former_company = core_sec10k__quarterly_company_information(raw_info)\n",
    "company_info = pd.concat(\n",
    "    [\n",
    "        company_data,\n",
    "        business_address,\n",
    "        mail_address,\n",
    "    ], axis=\"columns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Company Info\n",
    "\n",
    "### Company data\n",
    "- 3 of the 5 tables that can be pulled out of this data seem to pertain to companies -- static or slowly changing dimensions.\n",
    "- This data comes from the `business_address`, `mail_address` and `company_data` sub-tables.\n",
    "- If we concatenate these sets of columns together, what natural primary keys do we end up with.\n",
    "- Note that the `report_date` is not an independent field -- each filename seems to imply a specific report date.\n",
    "- The relationship between filename and report date seems to be naturally homed in the \"master filer\" table.\n",
    "- There's a directly reported CIK in the company data, but also a \"master filer\" CIK that can be extracted from the filename.\n",
    "- Having both the master filer and the company CIKs in the same table might be useful, and could indicate whether the company is a subsidiary.\n",
    "- The filename is mostly for provenance -- where did this data come from.\n",
    "- If the reported data fields (address, TIN, name, fiscal year, etc.) are truly identical, then we don't lose any information about the companies by deduplicating them.\n",
    "- We can drop the providencial / index information (filename, company & file information block counts) and then drop duplicates, and have a unique collection of company information.\n",
    "- In an ideal world this information would not include any CIK + date duplicates but...\n",
    "\n",
    "### Company naming history\n",
    "- There's a kind of \"sub-table\" that's associated with the company data, which describes the history of the company names.\n",
    "- The whole history seems to be reported in each filing, so there's lots of duplication.\n",
    "- Alone, this table only has the \"former\" names and the dates of changes away from those former names.\n",
    "- Being able to merge in the report date, filename, current company name and CIK from the company table will make this table more legible / useful.\n",
    "- With all of that information there will be a ton of duplication, but also probably lots of useful ways to deduplicate it in a subsequent step.\n",
    "- Maybe this is a raw or intermediate table that gets handed off for subsequent processing.\n",
    "\n",
    "### Filing data\n",
    "- There's also some filin-level data that's associatd with the company data.\n",
    "- On cursory inspection, it seems like a lot of the duplicate values that show up when trying to create a naturla primary key if we concatenate the filing data with the company data are actually due to the filing data.\n",
    "- If we separate the filing data out we may get a granular filing history that's separate from the less variable company data?\n",
    "- The same SEC filing number can show up many times because amendments and the filings they amend share the same filing number.\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On what basis is this table unique?\n",
    "\n",
    "# True!!!\n",
    "# company_info.index.is_unique\n",
    "\n",
    "# True!!!\n",
    "# company_info.reset_index().set_index([\"filename_sec10k\", \"filer_count\", \"company_information_block_count\"]).index.is_unique\n",
    "\n",
    "# False!!!\n",
    "# company_info.reset_index().set_index([\"filename_sec10k\", \"company_information_block_count\"]).index.is_unique\n",
    "\n",
    "# False!!!\n",
    "# company_info.reset_index().set_index([\"central_index_key\", \"report_date\"]).index.is_unique\n",
    "\n",
    "# False!!!\n",
    "# company_info.reset_index().set_index([\"filename_sec10k\", \"filer_count\"]).index.is_unique\n",
    "\n",
    "dude = company_info.reset_index().set_index([\"central_index_key\", \"report_date\"]).sort_index().reset_index()\n",
    "mask = dude.duplicated(subset=[\"central_index_key\", \"report_date\"], keep=False)\n",
    "#dude.loc[mask, ~dude.columns.str.match(f\"^(business_|mail_)\")].sort_values([\"central_index_key\", \"report_date\"]).head(50)\n",
    "dude.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude.drop(columns=[\"filename_sec10k\", \"filer_count\", \"company_information_block_count\"]).drop_duplicates().info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deduplicated = (\n",
    "    dude.drop(columns=[\"filename_sec10k\", \"filer_count\", \"company_information_block_count\"])\n",
    "    .drop_duplicates()\n",
    "    .set_index([\"central_index_key\", \"report_date\"])\n",
    "    .sort_index()\n",
    "    .reset_index()\n",
    ")\n",
    "dupes = deduplicated[deduplicated.duplicated(subset=[\"central_index_key\", \"report_date\"], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupes.set_index([\"central_index_key\", \"report_date\"]).head(500).tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_address.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filing_values.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_address.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude = (\n",
    "    former_company.reset_index()\n",
    "    .assign(\n",
    "        central_index_key=lambda x: x.filename_sec10k.str.split(\"/\").str[2].str.zfill(10),\n",
    "        name_change_date=lambda x: pd.to_datetime(x.date_of_name_change, format=\"%Y%m%d\")\n",
    "    )\n",
    "    .sort_values([\"central_index_key\", \"report_date\"])\n",
    "    .drop(columns=[\"date_of_name_change\"])\n",
    "    .drop_duplicates(subset=[\n",
    "        \"central_index_key\",\n",
    "        \"name_change_date\",\n",
    "        \"former_conformed_name\",\n",
    "    ], keep=\"last\")\n",
    "    .sort_values([\"central_index_key\", \"name_change_date\"])\n",
    ")\n",
    "display(dude.info())\n",
    "dude.head(50)[\n",
    "    [\n",
    "        \"central_index_key\",\n",
    "        \"name_change_date\",\n",
    "        \"former_conformed_name\",\n",
    "        \"report_date\",\n",
    "        \"filename_sec10k\",\n",
    "        \"filer_count\",\n",
    "        \"company_information_block_count\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_info[(raw_info.filer_count != raw_info.company_information_block_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_info[raw_info.filename_sec10k == \"edgar/data/105839/0000003673-94-000037.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 10-K Quarterly Filings\n",
    "\n",
    "The structure of this table generally seems good.\n",
    "\n",
    "Some field-level comments:\n",
    "\n",
    "* It would be helpful if the column descriptions for `filing_date` and `report_date` indicated the daily vs. quarterly frequencies or other different meanings that apply in the context of this resource (or maybe the whole SEC 10-K dataset?).\n",
    "* It seems as if `report_date` can be derived from `filing_date` -- that it's the first day of the quarter in which `filing_date` falls. If that's always true then technically we might not want it in the well normalized `core` tables, and could generate it in the output tables as needed. Is there a good reason to keep it? E.g. sometimes filings are late and pertain to a quarter other than the one it seems like they would?\n",
    "* It seems as if in the values in `central_index_key` need to be padded out to 10 characters with leading zeros in some contexts, e.g. [in this URL](https://data.sec.gov/submissions/CIK0000032377.json) and in the filenames that are listed in the `filename_sec10k` column. Are we stripping leading zeroes in the processing? Or are they coming from the structured SEC data that way? Interestingly any number of leading zeroes is accepted [in the Edgar URLs](https://www.sec.gov/edgar/browse/?CIK=00000000000000000000000000000000000000000000000000000000000000032377). Also interestingly, the field type is already `string`. The CIK values that show up in the company info table as values are also padded to 10 characters with leading zeroes.\n",
    "* `exhibit_21_version` seems to have a clean format, should we enforce it with a regex?\n",
    "* Is the `filename_sec10k` value something that's specific to our document store? Or does it reference something out in SEC-land?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sec10k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sec10k.sample(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 10-K Company Info\n",
    "\n",
    "* At first glance, it looks like there's a lot of normalization that could be done to this table that would clarify the relationships between the different values & entities.\n",
    "* The values under `company_information_fact_name` seem like they should be ~20 distinct columns, with the potential for lots of well defined data types for what would then be homogenous values coming out of `company_information_fact_value`. A handful of values appear malformed and could/should be cleaned up (`lstrip(\"]\")`)\n",
    "* Normalizing this table looks like it would drop the row count from ~8M to ~400K.\n",
    "* The fact that there are multiple blocks of the same kind of data in some cases seems to suggest that there are other embedded tables that could/should be stripped out and given a relationship to this table.\n",
    "* The primary key that's defined for this column is basically just all of the columns, which is a bit of a red flag.\n",
    "* It looks like there are at least 2 layers of normalized tables hiding in here?\n",
    "* Maybe:\n",
    "  * A `company` or SEC 10K filer table, with columns drawn from the `company_data`, `business_address` and `mail_address` blocks where the PK might be CIK + report date?\n",
    "  * A `filing` table drawn from the `filing_values` block that has a FK relationship with the `company` table.\n",
    "  * A company name changelog table drawn from the `former_company` block that also has a FK relationship with the `company` table.\n",
    "* I fiddled around with unstacking a bit (and maybe you did too) and it wasn't super simple because of the multiple nested tables, but the information in here seems like it's some of the valuable raw materials that are going to feed into the rest of the process -- e.g. the time evolution of company names and other values that we're going to try and do entity matching on. If this data was never normalized, how are we current going about extracting structured information from it for use in the document modeling / record linkage now?\n",
    "* Do we understand why there are multiple companies / filings contained in some files? What's the nature of the associations between the companies that show up in a single file? Does it provide any information about ownership? In the cases where there's more than one company associated with a given file, it seems like sometimes the CIK for each of those companies is different from the CIK referenced in the filename, which seems to correspond to the \"master filer\" referenced in the `core_sec10k__quarterly_filings` table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sec10k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df: pd.DataFrame = info_sec10k[\n",
    "    info_sec10k[\"company_information_fact_name\"] == \"central_index_key\"\n",
    "]\n",
    "df.duplicated(subset=[\"company_information_fact_value\", \"report_date\", \"filer_count\"]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sec10k.filer_count.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sec10k[\"company_information_fact_name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sec10k.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude = info_sec10k.set_index(\n",
    "    [\n",
    "        \"report_date\",\n",
    "        \"filename_sec10k\",\n",
    "        \"filer_count\",\n",
    "        \"company_information_block\",\n",
    "        \"company_information_block_count\",\n",
    "        \"company_information_fact_name\"\n",
    "    ]\n",
    ").unstack(level=\"company_information_fact_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dude.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_sec10k[info_sec10k.filename_sec10k == \"edgar/data/105839/0000003673-94-000037.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_sec10k.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 10-K Ownership Information\n",
    "\n",
    "* We know what file each row came from, but in many cases there are multiple companies referenced in individual 10-K files. How do we decide which one of those companies should be considered the parent? I.e. who owns the `fraction_owned`?\n",
    "* There seems to be a CIK embedded in the filename. Is that important for linking this data back to the company info table? I guess we can also go indirectly to CIK via the filename listed here and in the filings table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "own_sec10k.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SEC 10-K Parent / Subsidiary Table\n",
    "\n",
    "* This is a denormalized association table that relates parents to subsidiaries.\n",
    "* It should probably correspond to a very skinny normalized association table that describes just the associations using IDs, without any of the data columns, but which can be used as the backbone for merging in data from one or more other tables that contain the specific data about the parent and subsidiary companies.\n",
    "* How many different kinds of companies are there, and how do they relate to each other? Can/Should the parent and subsidiary companies be described using the same data structure?\n",
    "* Every column in this table should be named such that it is clear whether the attribute is associated with the parent or the subsidiary company, since there are two sets of basically similar information in the table side-by-side, e.g. with a `parent_` and `subsidiary_` prefix.\n",
    "* Based on the other tables it seems like there might be as many as 3 different kinds of companies we're dealing with, or about which we might have different kinds and amounts of information.\n",
    "  * The (master filer?) company listed in the `core_sec10k__quarterly_filings` table.\n",
    "  * The individual companies listed in un-normalized sub-tables of `core_sec10k__company_information`.\n",
    "  * The subsidiary companies in `core_sec10k_quarterly_exhibit_21_company_ownership` about which may only have a name, or at best a name, location, and fraction of that company that's owned by some parent.\n",
    "* Maybe the master filers / individual companies can be described using the same structure because that information is ultimately available for all SEC 10-K filers?\n",
    "* Any company that we're pulling from the filing or company info tables will have a CIK associated with it so we can probably use that to look up (time varying) information about the company somehow.\n",
    "* The raw company info that we're pulling Exhibit 21 initially won't be guaranteed to have anything but a name (and a filename / report date), but then we use that to do some entity matching, and create an association table between the Exhibit 21 companies and other SEC 10-K filers.\n",
    "* There should be an Exhibit 21 company table that has its own primary key that's hopefully eventually associated with one of the real SEC 10-K filer records.\n",
    "* Because ownership can change over time, with subsidiaries being sold off to other companies, it seems like we have to maintain a sense of time variability in these associations. Otherwise the data won't be useful for answering questions like \"In 2020Q2 when this dodgy transaction took place between companies A and B, where they owned by the same parent company?\"\n",
    "* What does it mean if in a given year a subsidiary shows up in Exhibit 21 for a parent company, and in the subsequent year it does **not** show up in Exhibit 21 for that same parent company? It seems like that should imply that it's no longer owned by the parent. Is there a reason why we wouldn't be able to say that?\n",
    "* Once the entity matching has been done within the SEC 10-K data, connecting the sparse information we have about many subsidiary companies back to fuller information about the SEC 10-K filers, then we have a table of company information we can try to match against the EIA utility data.\n",
    "\n",
    "### Company Tables\n",
    "\n",
    "* SEC 10-K filers (lots of columns, PK is probably CIK?)\n",
    "* Exhibit 21 Subsidiaries (very few columns, PK is probably messy/name-based, or an auto-incrementing pseudo-key)\n",
    "* EIA Utilities (lots of columns from PUDL)\n",
    "* Normalized (skinny) association table that links SEC 10-K filers and Exhibit 21 Subsidiaries, based on record linkage.\n",
    "* Denormalized table that merges in all relevant company-level attributes from both SEC 10-K filers and Exhibit 21 Subsidiaries tables\n",
    "* Many companies will show up only as one or the other, some as both, so this denormalized table would have a lot of null fields.\n",
    "* Right now it seems like `company_id_sec10k` is the column that represents the primary key of this merged company table, but it's a mix of CIKs and concatenated values from the Exhibit 21 table which is a messy mix that can lead to confusion (we were bitten by a similar pattern in the EIA utility and/or BA IDs in the FERC-714 data).\n",
    "* This denormalized SEC 10-K table seems like the thing that would have been used in record linkage against the EIA utilities, since it has the most SEC based company information? In which case there would also potentially be a `utility_id_eia` column for use connecting the SEC 10-K companies to the EIA utilities.\n",
    "\n",
    "### SEC 10-K Filer (entity) Table\n",
    "\n",
    "* `central_index_key`\n",
    "* Are there any other truly permanent company fields linked to the CIK?\n",
    "\n",
    "### SEC 10-K Filer (time-varying) company info table\n",
    "\n",
    "* `central_index_key` (PK)\n",
    "* `report_date` (PK)\n",
    "* Any other time-varying, per-company fields that fall out of the normalization of `core_sec10k__quarterly_company_information`\n",
    "\n",
    "### Exhibit 21 Company (entity) Table\n",
    "\n",
    "Notionally this would contain any permanent attributes of the companies observed as subsidiaries in Exhibit 21. Since that table is almost unstructured, this one is probably vestigal and doesn't need to exist.\n",
    "\n",
    "* `company_id_ex21`\n",
    "* ???\n",
    "\n",
    "### Exhibit 21 (time-varying) Company Table\n",
    "\n",
    "All the unique **company** information that's been extracted from Exhibit 21 attachements. Note that this doesn't include the ownership fraction, which ends up in a table that is about the data that's unique to the parent-subsidiary relationship.\n",
    "\n",
    "* `company_id_ex21` (PK, auto-incrementing integer pseudo-key?)\n",
    "* `report_date` (data)\n",
    "* `parent_central_index_key` (data, extracted from `filename_sec10k`?)\n",
    "* `subsidiary_company_name` (data)\n",
    "* `subsidiary_company_location` (data)\n",
    "* `filename_sec10k` (data)\n",
    "\n",
    "### SEC 10-K Company (Filer and/or Subsidiary) Association Table\n",
    "\n",
    "Links companies that have been observed as both SEC 10-K filers and Exhibit 21 subsidiaries, based on statstical record linkage.  There's no explicit time variability in this table, but the fact that some companies only show up in some years means there's an implicity time dependence, which will show up in other tables with `report_date` columns.\n",
    "\n",
    "* `company_id_sec10k` (PK)\n",
    "* `company_id_ex21` (PK)\n",
    "* `central_index_key` (PK)\n",
    "\n",
    "### Parent-subsidiary association table\n",
    "\n",
    "A normalized table that contains just the information that is unique to the association between a parent and subsidiary company pair. This can be used to merge together other pieces of information about the parent and/or subsidiary to create useful denormalized output table. Each row says \"On this date, this parent owned this fraction of this subsidiary.\"\n",
    "\n",
    "* `report_date` (PK)\n",
    "* `parent_company_id_sec10k` (PK)\n",
    "* `subsidiary_company_id_sec10k` (PK)\n",
    "* `fraction_owned` (data)\n",
    "\n",
    "### SEC 10-K Company Output Table\n",
    "\n",
    "A wide, human-readable denormalized table that merges together all of the relevant information about a company that we have extracted from the SEC 10-K filings, whether that information comes from the core SEC 10-K filings, Exhibit 21 attachments, or EIA Utilities data we have in PUDL.\n",
    "\n",
    "* `company_id_sec10k` (PK)\n",
    "* `report_date` (PK)\n",
    "* `central_index_key` (data)\n",
    "* `company_id_ex21` (data)\n",
    "* `utility_id_eia` (data)\n",
    "* Other data columns to be selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sec10k.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sec10k.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interchange = get_parquet(\"core_eia930__hourly_interchange\")\n",
    "gen_by_source = get_parquet(\"core_eia930__hourly_net_generation_by_energy_source\")\n",
    "operations = get_parquet(\"core_eia930__hourly_operations\")\n",
    "demand = get_parquet(\"core_eia930__hourly_subregion_demand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operations[operations.demand_imputed_mwh.notna()].filter(like=\"demand\").sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 - operations.filter(like=\"demand\").isna().sum() / len(operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec10k = get_table(\"out_sec10k__parents_and_subsidiaries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec10k.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pudl-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
